---
title: "Generalized Least Squares"
author: "Lukas"
date: "2023-03-30"
output: html_document
---

```{r}
library(nlme)
library(lme4)
library(VGAM)
library(car)
library(doParallel)
library(parallel)
library(foreach)
library(vars)
library(astsa)
```



Load MATLAB Data
```{r}
Aug_08 <- read.csv("C:\\Users\\buhl5\\Desktop\\Plan B Files\\PMA17\\Aug_08_table.csv")
Aug_09 <- read.csv("C:\\Users\\buhl5\\Desktop\\Plan B Files\\PMA17\\Aug_09_table.csv")
Aug_12 <- read.csv("C:\\Users\\buhl5\\Desktop\\Plan B Files\\PMA17\\Aug_12_table.csv")
Aug_15 <- read.csv("C:\\Users\\buhl5\\Desktop\\Plan B Files\\PMA17\\Aug_15_table.csv")
Oct_12 <- read.csv("C:\\Users\\buhl5\\Desktop\\Plan B Files\\PMA17\\Oct_12_table.csv")
```

Remove Bad Tones from August 8th

```{r}
Aug_08 <- Aug_08[-c(1:60),]
```

Relabel Days
```{r}
Aug_08$Day <- 1
Aug_09$Day <- 2
Aug_12$Day <- 3
Aug_15$Day <- 4
Oct_12$Day <- 5
```



Day will likely be more useful when the days are all ran together with no gaps

Full Ephys Dataset
```{r}
Data <- rbind(Aug_08,Aug_09,Aug_12,Aug_15)
Test_Data <- Oct_12
rm(Aug_08,Aug_09,Aug_12,Aug_15,Oct_12)
```


Factors
```{r}
Data$Bin <- as.factor(Data$Bin)
```


Load Behavior Data
```{r}
## I Need to run August 5th through Analysis
Aug_08_Behav <- read.csv("C:\\Users\\buhl5\\Downloads\\08_08_new_R_TB_PMA17.csv")
Aug_09_Behav <- read.csv("C:\\Users\\buhl5\\Downloads\\08_09_new_R_TB_PMA17.csv")
Aug_12_Behav <- read.csv("C:\\Users\\buhl5\\Downloads\\08_12_new_R_TB_PMA17.csv")
Aug_15_Behav <- read.csv("C:\\Users\\buhl5\\Downloads\\08_15_new_R_TB_PMA17.csv")
Oct_12_Behav <- read.csv("C:\\Users\\buhl5\\Downloads\\10_12_new_R_TB_PMA17.csv")
```

Pull Time Specific Bins currently time 0 to 29. Will likely be adjusted to only tones

```{r}
Aug_08_Behav_p  <-  Aug_08_Behav[Aug_08_Behav[,2] %in% c(0:29),3]
Aug_09_Behav_p  <-  Aug_09_Behav[Aug_09_Behav[,2] %in% c(0:29),3]
Aug_12_Behav_p  <-  Aug_12_Behav[Aug_12_Behav[,2] %in% c(0:29),3]
Aug_15_Behav_p  <-  Aug_15_Behav[Aug_15_Behav[,2] %in% c(0:29),3]
Oct_12_Behav_p  <-  Oct_12_Behav[Oct_12_Behav[,2] %in% c(0:29),3]
```

All Behave

```{r}
#Remove same August Stuff
Aug_08_Behav_p <- Aug_08_Behav_p[-c(1:60)]
Behave <- c(Aug_08_Behav_p,Aug_09_Behav_p,Aug_12_Behav_p,Aug_15_Behav_p)

Test_Data$Platform <- Oct_12_Behav_p
Data$Platform <- Behave
```


Clean
```{r}
rm(Aug_08_Behav,Aug_09_Behav,Aug_12_Behav,Aug_15_Behav,Oct_12_Behav)
rm(Aug_08_Behav_p,Aug_09_Behav_p,Aug_12_Behav_p,Aug_15_Behav_p,Oct_12_Behav_p,Behave)
```

Data needs to be adjusted to accommodate 0 and 1

```{r}
#Playing it safe using a loop

offset <- 0.02


for(i in 1:length(Data$Platform)){
  
  if(Data$Platform[i] == 0){Data$Platform[i] <- offset}
  if(Data$Platform[i] == 1){Data$Platform[i] <- 1 - offset}
}

for(i in 1:length(Test_Data$Platform)){
  
  if(Test_Data$Platform[i] == 0){Test_Data$Platform[i] <- offset}
  if(Test_Data$Platform[i] == 1){Test_Data$Platform[i] <- 1 - offset}
}
```

Transform Response to make it fit regression requirement
```{r}
Data$probitPlatform <- probitlink(Data$Platform)
Test_Data$probitPlatform <- probitlink(Test_Data$Platform)
Test_Data.gls <- Test_Data
```
#### Model Fitting #####


OLS
```{r}
AIC.lm = lm(probitPlatform~1+Day+Tone+Bin,data=nesting.info)
AIC.lm.full = lm(probitPlatform~.,data=nesting.info)
step.mod.lm = MASS::stepAIC(AIC.lm,scope = list(lower = AIC.lm, upper = AIC.lm.full) ,direction = "forward",trace=F)
plot(step.mod.lm)
acf(step.mod.lm$residuals)
pacf(step.mod.lm$residuals)
dwt(as.numeric(step.mod.lm$residuals),max.lag = 30)
```

Assumption plots do not look great, residuals have a significant autocorrelation structure.
Will refit with ARMA errors as suggested by previous model fits




Longitudinal
```{r}
gls.data <- Data[,c(1:39,113)]

gls.data$Bin <- as.ordered(gls.data$Bin)
nesting.info <- groupedData(probitPlatform~1|Day/Tone/Bin,data=gls.data)

test.fit.gls.ts <- gls(probitPlatform~Day+Tone+Bin,data=nesting.info,correlation = corARMA(,form=~1|Day/Tone,p=1,q=2),method = "ML")
```


Stepwise Longitudinal Model


```{r}
test_candidate_model_gls_ts <- function(gls.var.available,i){
  candidate_model <- nlme::gls(as.formula(paste("probitPlatform~",paste(c(model_var_gls,gls.var.available[i]),collapse="+"))),data=nesting.info,correlation = nlme::corARMA(,form=~1|Day/Tone,p=1,q=2),method = "ML")
   
   test_aic <- extractAIC(candidate_model)[2]
   return(test_aic)
}
```




```{r}
model_var_gls_ts <- c("Day","Tone","Bin")
gls.var <- names(nesting.info)[-c(1:3,40)]
gls.var.available_ts <- gls.var

best_aic_gls_ts <- extractAIC(test.fit.gls.ts)[2]

check <-  F

cl <- parallel::makeCluster(14)
doParallel::registerDoParallel(cl)


while(check == F){
  
  candidates <- foreach::foreach(i = 1:length(gls.var.available), .combine = cbind) %dopar% {
    test_candidate_model_gls_ts(gls.var.available = gls.var.available, i=i)
  }
  
  if(min(candidates) >= best_aic_gls_ts){check = T}  
  
  if(min(candidates) < best_aic_gls_ts & check == F){
    best_aic_gls_ts <- min(candidates)
    model_var_gls_ts <- c(model_var_gls,gls.var.available[sort(candidates,index.return=T)$ix[1]])
    gls.var.available_ts <- gls.var.available[-sort(candidates,index.return=T)$ix[1]]
    }  
  print("Iteration")
}

parallel::stopCluster(cl)
model_var_gls_ts

```


Final Model by AIC
```{r}
AIC_mod.gls <- gls(as.formula(paste("probitPlatform~",paste(model_var_gls,collapse="+"))),data=nesting.info,correlation = nlme::corARMA(,form=~1|Day/Tone,p=1,q=2),method = "ML")

summary(AIC_mod.gls)
```

Predictions
```{r}
ols.with.gls.coef <- lm(as.formula(paste("probitPlatform~",paste(model_var_gls,collapse="+"))),data=nesting.info)


pred.data <- as.data.frame(Test_Data.gls)
pred.data.ols <- as.data.frame(Test_Data.gls)
pred.var <- names(AIC_mod.gls$coefficients)[-c(1:32)]
pred.var.ols <- names(step.mod.lm$coefficients)[-c(1:32)]
pred.var <- c("Day","Tone","Bin",pred.var)
pred.var.ols <- c("Day","Tone","Bin",pred.var.ols)
pred.data <- pred.data[,pred.var]
pred.data.ols <- pred.data.ols[,pred.var.ols]
pred.data$Bin <- as.ordered(pred.data$Bin)
pred.data.ols$Bin <- as.ordered(pred.data.ols$Bin)
pred.ols.mod <- predict(step.mod.lm,newdata = pred.data.ols,na.action = NULL)
pred.gls.mod <- predict(AIC_mod.gls,newdata = pred.data,na.action = NULL)
pred.ols.mod.gls.coef <-  predict(ols.with.gls.coef,newdata = pred.data,na.action = NULL)
sum((as.numeric(Test_Data[,113]) - pred.ols.mod)^2)
sum((as.numeric(Test_Data[,113]) - pred.ols.mod.gls.coef)^2)
sum((as.numeric(Test_Data[,113]) - pred.gls.mod)^2)
```

Diagnostic Plots
```{r}
pdf(file = "C:\\Users\\buhl5\\Desktop\\Plot PDFs\\GLS_AIC_RF.pdf",
    width = 6,
    height =4)
plot(AIC_mod.gls$fitted,AIC_mod.gls$residuals, main = "GLS by AIC Residuals vs Fitted", xlab = "Fitted Values", ylab = "Residuals")
dev.off()
```


Anova Test
```{r}
anova(AIC_mod.gls)
```

Testing Non-linear Time
```{r}
AIC_mod.gls.poly2 <- gls(probitPlatform ~ poly(Day,2) + poly(Tone,2) + Bin + ILBLA_mean_High_Beta + PLBLA_mean_High_Beta + 
    IL_pow_mean_Low_Beta + BLA_pow_mean_Alpha + ILPL_mean_High_Beta + 
    ILBLA_mean_Mid_Beta + BLA_pow_mean_Mid_Beta + PL_pow_mean_High_Beta + 
    PL_pow_mean_Low_Beta + PL_pow_mean_Theta + PLBLA_mean_Delta,data=nesting.info,correlation = nlme::corARMA(,form=~1|Day/Tone,p=1,q=2),method = "ML")

pred.gls.mod.poly2 <- predict(AIC_mod.gls.poly2,newdata = pred.data,na.action = NULL)
sum((as.numeric(Test_Data[,113]) - pred.gls.mod.poly2)^2)
anova(AIC_mod.gls,AIC_mod.gls.poly2)
par(mfrow = c(1,2))
plot(AIC_mod.gls.poly2$fitted,AIC_mod.gls$residuals)
qqnorm(AIC_mod.gls.poly2$residuals)
abline(0,1)
dwt(as.numeric(AIC_mod.gls.poly2$residuals),max.lag = 30)
```


Auto Arima on residuals
```{r}
auto.res <- auto.arima(ts(AIC_mod.gls.poly2$residuals), stationary = T,  seasonal = F, stepwise = F,ic = "aic",max.p = 5, max.q = 10, max.P = 0, max.Q = 0, max.order = 50,trace = F, test = "adf",approximation = T)
summary(auto.res)
```

Auto ARIMA suggests refitting with (1,0,5)
```{r}
refit.gls <- gls(probitPlatform ~ poly(Day,2) + poly(Tone,2) + Bin + ILBLA_mean_High_Beta + PLBLA_mean_High_Beta + 
    IL_pow_mean_Low_Beta + BLA_pow_mean_Alpha + ILPL_mean_High_Beta + 
    ILBLA_mean_Mid_Beta + BLA_pow_mean_Mid_Beta + PL_pow_mean_High_Beta + 
    PL_pow_mean_Low_Beta + PL_pow_mean_Theta + PLBLA_mean_Delta,data=nesting.info,correlation = nlme::corARMA(,form=~1|Day/Tone,p=1,q=5),method = "ML")

pred.refit.gls <- predict(refit.gls,newdata = pred.data,na.action = NULL)
sum((as.numeric(Test_Data[,113]) - pred.refit.gls)^2)
anova(AIC_mod.gls,AIC_mod.gls.poly2,refit.gls)
par(mfrow = c(1,2))
plot(refit.gls$fitted,refit.gls$residuals)
qqnorm(refit.gls$residuals)
abline(0,1)
dwt(as.numeric(refit.gls$residuals),max.lag = 30)
```

```{r}
auto.res.2 <- forecast::auto.arima(ts(refit.gls$residuals), stationary = T,  seasonal = F, stepwise = F,ic = "aic",max.p = 5, max.q = 10, max.P = 0, max.Q = 0, max.order = 50,trace = F, test = "adf",approximation = T)
summary(auto.res.2)
```

Auto ARIMA suggests refitting with (1,0,3)
```{r}
refit.gls.2 <- gls(probitPlatform ~ poly(Day,2) + poly(Tone,2) + Bin + ILBLA_mean_High_Beta + PLBLA_mean_High_Beta + 
    IL_pow_mean_Low_Beta + BLA_pow_mean_Alpha + ILPL_mean_High_Beta + 
    ILBLA_mean_Mid_Beta + BLA_pow_mean_Mid_Beta + PL_pow_mean_High_Beta + 
    PL_pow_mean_Low_Beta + PL_pow_mean_Theta + PLBLA_mean_Delta,data=nesting.info,correlation = nlme::corARMA(,form=~1|Day/Tone,p=1,q=3),method = "ML")

pdf(file = "C:\\Users\\buhl5\\Desktop\\Plot PDFs\\GLS_poly_RF.pdf",
    width = 6,
    height =4)
plot(refit.gls.2$fitted,refit.gls.2$residuals, main = "GLS with Quadratic Terms Residuals vs Fitted", xlab = "Fitted Values", ylab = "Residuals")
dev.off()

pred.refit.gls.2 <- predict(refit.gls.2,newdata = pred.data,na.action = NULL)
sum((as.numeric(Test_Data[,113]) - pred.refit.gls.2)^2)
anova(AIC_mod.gls,AIC_mod.gls.poly2,refit.gls.2)
par(mfrow = c(1,2))

qqnorm(refit.gls.2$residuals)
abline(0,1)
dwt(as.numeric(refit.gls.2$residuals),max.lag = 30)
```

Anova Suggests Stepping it up
```{r}
AIC_mod.gls.poly3 <- gls(probitPlatform ~ poly(Day,2) + poly(Tone,3) + Bin + ILBLA_mean_High_Beta + PLBLA_mean_High_Beta + 
    IL_pow_mean_Low_Beta + BLA_pow_mean_Alpha + ILPL_mean_High_Beta + 
    ILBLA_mean_Mid_Beta + BLA_pow_mean_Mid_Beta + PL_pow_mean_High_Beta + 
    PL_pow_mean_Low_Beta + PL_pow_mean_Theta + PLBLA_mean_Delta,data=nesting.info,correlation = nlme::corARMA(,form=~1|Day/Tone,p=1,q=1),method = "ML")

pred.gls.mod.poly3 <- predict(AIC_mod.gls.poly3,newdata = pred.data,na.action = NULL)
sum((as.numeric(Test_Data[,113]) - pred.gls.mod.poly3)^2)
anova(AIC_mod.gls,AIC_mod.gls.poly2,AIC_mod.gls.poly3)
```


One more
```{r}
auto.res.3 <- auto.arima(ts(refit.gls.2$residuals), stationary = T,  seasonal = F, stepwise = F,ic = "aic",max.p = 5, max.q = 10, max.P = 0, max.Q = 0, max.order = 50,trace = F, test = "adf",approximation = T)
summary(auto.res.3)
```

OLS final
```{r}
ols.final <- lm(probitPlatform ~ poly(Day,2) + poly(Tone,2) + Bin + ILBLA_mean_High_Beta + PLBLA_mean_High_Beta + 
    IL_pow_mean_Low_Beta + BLA_pow_mean_Alpha + ILPL_mean_High_Beta + 
    ILBLA_mean_Mid_Beta + BLA_pow_mean_Mid_Beta + PL_pow_mean_High_Beta + 
    PL_pow_mean_Low_Beta + PL_pow_mean_Theta + PLBLA_mean_Delta,data=nesting.info)
ols.coef <- ols.final$coefficients
```


final 3 comparison
```{r}
pred.data <- as.data.frame(Test_Data.gls)
pred.data.ols <- as.data.frame(Test_Data.gls)
pred.var <- names(AIC_mod.gls$coefficients)[-c(1:32)]

pred.var <- c("Day","Tone","Bin",pred.var)

pred.data <- pred.data[,pred.var]

pred.data$Bin <- as.ordered(pred.data$Bin)

pred.ols.mod <- predict(ols.final,newdata = pred.data,na.action = NULL)
pred.gls.mod <- predict(refit.gls.2,newdata = pred.data,na.action = NULL)
TS_predict_Day <- predict(start_model_means,n.ahead = 600)

(OLS_MSE_Day <- sum((as.numeric(Test_Data[,113]) - pred.ols.mod)^2))
(TS_MSE_Day <- sum((as.numeric(Test_Data[,113]) - as.numeric(TS_predict_Day[["pred"]]))^2))
(GLS_MSE_Day <- sum((as.numeric(Test_Data[,113]) - pred.gls.mod)^2))
```




Compare to TS
```{r}

plot(Test_Data.gls$probitPlatform,ylim = c(-3,3), main = "Predicted Values and Real Data", ylab = "Probit Platform", xlab = "Bin Number")
lines(1:600,TS_predict_Day[["pred"]], col = "blue",pch = "*", lty = 1)
lines(1:600,pred.gls.mod, col = "red", pch = "+", lty = 2)
lines(1:600,pred.ols.mod, col = "orange",pch = "o", lty = 3)
legend("topleft",c("Data", "Time Series", "GLS", "OLS"), col = c("black", "blue", "red", "orange"), pch = c("o","*","+","o"),lty=c(0,1,2,3), ncol=1,cex = 1)

```

Anova Test of Variables
```{r}
car::Anova(refit.gls.2)
par(mfrow = c(1,2))
plot(refit.gls.2$fitted,refit.gls.2$residuals)
qqnorm(refit.gls.2$residuals)
abline(0,1)
plot(refit.gls.2)
sum <- summary(refit.gls.2)
View(sum$tTable)
```

Plots
```{r}
pdf(file = "C:\\Users\\buhl5\\Desktop\\Plot PDFs\\prediction.pdf",
    width = 12,
    height =5)
plot(Test_Data.gls$probitPlatform[1:180],ylim = c(-3,3), main = "Predicted Values and Real Data", ylab = "Probit Platform", xlab = "Bin Number", type = "l",lwd = 3)
lines(1:180,TS_predict_Day[["pred"]][1:180], col = "blue",pch = "*", lty = 1, lwd = 3)
lines(1:180,pred.gls.mod[1:180], col = "red", pch = "+", lty = 1, lwd =3)
lines(1:180,pred.ols.mod[1:180], col = "orange",pch = "o", lty = 1, lwd =3)
legend("bottomright",c("Data", "Time Series", "GLS", "OLS"), col = c("black", "blue", "red", "orange"),lty=c(1,1,1,1), ncol=1,cex = 1)
dev.off()
```




